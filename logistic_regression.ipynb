{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы анализа данных\n",
    "\n",
    "## Тема 3. Классификация. Логистическая регрессия\n",
    "\n",
    "#### Задание 1. \n",
    "Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['choose', 'Id'], axis=1)\n",
    "\n",
    "y = train['choose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция масштабирования признаков методом стандартизации\n",
    "\n",
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res\n",
    "\n",
    "X_st = X.copy()\n",
    "X_st.iloc[1, :] = calc_std_feat(X.iloc[1, :])\n",
    "X_st.iloc[2, :] = calc_std_feat(X.iloc[2, :])\n",
    "X_st.iloc[3, :] = calc_std_feat(X.iloc[3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходная функция calc_logloss\n",
    "\n",
    "def calc_logloss(y, y_pred):\n",
    "    \n",
    "    err = -np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "   \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Измененная функция\n",
    "\n",
    "def calc_logloss(y, y_pred):\n",
    "    tol = 1e-5\n",
    "    y_pred = y_pred.copy()\n",
    "    y_pred = np.clip(y_pred, a_min=tol, a_max=1-tol) # clip - ограничивает прогнозы\n",
    "    \n",
    "    score = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "   \n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2. \n",
    "Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=1e-4, tol=1e-5): # Функция обучения модели\n",
    "    \n",
    "    np.random.seed(23)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    errors, weights = [], []\n",
    "    \n",
    "    for n_iter in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        current_error = calc_logloss(y, y_pred)\n",
    "        W = W - alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        \n",
    "        errors.append(current_error)\n",
    "        weights.append(W)\n",
    "        \n",
    "        if n_iter > 2 and np.abs(current_error - errors[-2]) < tol: # Критерий остановки\n",
    "            break\n",
    "            \n",
    "    errors = np.array(errors)\n",
    "    return errors, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3.\n",
    "Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W: np.array, X: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Применение обученной модели логистической регрессии\n",
    "    для матрицы признаков x, получение прогнозов модели.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    W: np.array\n",
    "        Веса обученной модели\n",
    "        \n",
    "    X: np.array\n",
    "        Матрица признаков\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "    \n",
    "    \"\"\"\n",
    "    y_pred = 1 / (1 + np.exp(-np.dot(W, X)))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 4.\n",
    "Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X, threshold: float=0.5) -> np.array:\n",
    "    \"\"\"\n",
    "    Применение обученной модели логистической регрессии\n",
    "    для матрицы признаков X, получение лейблов классов.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    W: np.array\n",
    "        Веса обученной модели.\n",
    "        \n",
    "    X: np.array\n",
    "        Матрица признаков\n",
    "        \n",
    "    threhold: float, optional, default = 0.5.\n",
    "        Порог, при котором объект относится к целевому классу.\n",
    "        Опциональный параметр, по умолчанию равен 0.5.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "    \n",
    "    \"\"\"\n",
    "    y_pred = calc_pred_proba(W, X)\n",
    "    y_pred = np.where(y_pred > threshold, 1, 0)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 5.\n",
    "Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true: np.array, y_pred: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Вычисление значения метрики Accuracy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор истинных ответов\n",
    "    \n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score: float\n",
    "        Значение метрики Accuracy\n",
    "    \n",
    "    \"\"\"\n",
    "    mask = y_true == y_pred\n",
    "    \n",
    "    return sum(mask) / y_true.shape[0]\n",
    "\n",
    "def confusion_matrix(y_true: np.array, y_pred: np.array):\n",
    "    \"\"\"\n",
    "    Вычисление матрицы ошибок.\n",
    "    Возвращение значения при плоском векторе: tn, fp, fn, tp.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор истинных ответов\n",
    "    \n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    conf_matrix: np.array\n",
    "        Матрица ошибок.\n",
    "    \n",
    "    \"\"\"\n",
    "    conf_matrix = np.zeros(shape=(2, 2))\n",
    "    conf_matrix[0, 0] = np.sum(np.where(y_true == 0, y_pred == y_true, False))\n",
    "    conf_matrix[1, 1] = np.sum(np.where(y_true == 1, y_pred == y_true, False))\n",
    "    conf_matrix[1, 0] = np.sum(np.where(y_true == 1, y_pred != y_true, False))\n",
    "    conf_matrix[0, 1] = len(y_true) - conf_matrix.sum()\n",
    "    \n",
    "    return conf_matrix.astype(int)\n",
    "\n",
    "def precision_score(y_true: np.array, y_pred: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Вычисление значения метрики precision.\n",
    "    # конверсия TP / (TP + FP)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор истинных ответов\n",
    "    \n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score: float\n",
    "        Значение метрики precision.\n",
    "    \n",
    "    \"\"\"\n",
    "    _, fp, _, tp = confusion_matrix(y_true, y_pred).flatten()\n",
    "    score = tp / (tp + fp)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def recall_score(y_true: np.array, y_pred: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Вычисление значения метрики recall.\n",
    "    # Доля ЦА TP / (TP + FN)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор истинных ответов\n",
    "    \n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score: float\n",
    "        Значение метрики recall.\n",
    "    \n",
    "    \"\"\"\n",
    "    _, _, fn, tp = confusion_matrix(y_true, y_pred).flatten()\n",
    "    score = tp / (tp + fn)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def f1_score(y_true: np.array, y_pred: np.array, betta: float=0.5) -> float:\n",
    "    \"\"\"\n",
    "    Вычисление значения метрики F1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор истинных ответов\n",
    "    \n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов\n",
    "        \n",
    "    betta: float\n",
    "        Вес для регулирования важности между метриками precision / recall.\n",
    "        Опциональный параметр, по умолчанию равен 0.5.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score: float\n",
    "        Значение метрики F1.\n",
    "    \n",
    "    \"\"\"\n",
    "    precision, recall = precision_score(y_true, y_pred), recall_score(y_true, y_pred)\n",
    "    score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 6.\n",
    "Могла ли модель переобучиться? Почему?\n",
    "\n",
    "Да, модель могла переобучиться, т.к. очень маленьких набор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 7. \n",
    "Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризацией соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_with_regularization(X: np.array,\n",
    "                                   y: np.array, \n",
    "                                   iterations: int = 100000, \n",
    "                                   alpha: float = 0.01, \n",
    "                                   tol: float = 1e-5,\n",
    "                                   c1: float = 0., # коэф. L1-регуляризации\n",
    "                                   c2: float = 0.): # коэф. L2-регуляризации\n",
    "    \"\"\"\n",
    "    Модель логистической регресси с L1-регуляризацией и L2-регуляризацией.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: np.array\n",
    "        Матрица признаков для обучения\n",
    "    \n",
    "    y: np.array\n",
    "        Вектор целевой переменной для обучения\n",
    "    \n",
    "    iterations:int, optional, default = 100000\n",
    "        Количество итераций обучения. Опциональный параметр,\n",
    "        по умолчанию равен 100000.\n",
    "    \n",
    "    alpha: float, optional, default = 0.01\n",
    "        Скорость обучения. Опциональный параметр,\n",
    "        по умолчанию равен 0.01\n",
    "    \n",
    "    tol: float, optional, default = 1e-5\n",
    "        Минимальное значение изменение ошибки, при котором\n",
    "        обучение продолжается. Если изменение ошибки на соседних \n",
    "        итерациях меньше указанной величины, то обучение прекращается.\n",
    "    \n",
    "    c1: float, optional, default = 0\n",
    "        Коэффициент L1-регуляризации.\n",
    "        Опциональный параметр, по умолчанию равен 0.\n",
    "    \n",
    "    c2: float = 0\n",
    "        Коэффициент L2-регуляризации.\n",
    "        Опциональный параметр, по умолчанию равен 0.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    errors, weights = [], []\n",
    "    \n",
    "    for n_iter in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        current_error = calc_logloss(y, y_pred)\n",
    "        W = W - alpha * (1/n * np.dot((y_pred - y), X.T)) + 2 * c2 * W + 0.5 * c1 * W/np.abs(W)\n",
    "        \n",
    "        errors.append(current_error)\n",
    "        weights.append(W)\n",
    "        \n",
    "        if n_iter > 2 and np.abs(current_error - errors[-2]) < tol: # Критерий остановки\n",
    "            break\n",
    "            \n",
    "    errors = np.array(errors)\n",
    "    return errors, weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
